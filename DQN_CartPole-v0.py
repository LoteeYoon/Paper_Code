# -*- coding: utf-8 -*-
"""DQN_CartPole-v0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q-hQQEtaH08VsUMwRqhoDF9ybKLHPNh4
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import gym
import numpy as np
import matplotlib.pyplot as plt
import sys, os
from IPython.display import clear_output
from typing import List

class Network(nn.Module):
    def __init__(self, obs_dim: int, act_dim: int):
        super(Network, self).__init__()

        self.obs_dim = obs_dim
        self.act_dim = act_dim
        self.fc1 = nn.Linear(self.obs_dim, 128)
        self.fc2 = nn.Linear(128, 128)
        self.fc3 = nn.Linear(128, self.act_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x

class ReplayBuffer:
    def __init__(self, size: int, batch_size: int):
        self.size = 0
        self.batch_size = batch_size
        self.max_size = size
        self.trainsition = []
        self.replay = []
        self.sample_index = []
        self.train_batch = []
        self.ptr = 0
        

    def store(self, 
              prev_obs: List[float],
              action: float,
              reward: float,
              obs: List[float],
              done: bool,
              ):
        self.transition = [prev_obs, action, reward, obs, done]
        self.replay.insert(self.ptr, self.transition)
        self.ptr = (self.ptr + 1) % self.max_size
        self.size = min(self.size + 1, self.max_size)


    def sample_batch(self) -> List[int]:
        self.sample_index = np.random.randint(low=0, high=self.size, size=self.batch_size)
        self.train_batch = [self.replay[idx] for idx in self.sample_index]
        return self.train_batch

class Agent:
    def __init__(self, 
                 env: gym.Env,
                 memory_size: int,
                 batch_size: int,
                 target_update: int,
                 epsilon_decay: float,
                 max_epsilon: float,
                 min_epsilon: float,
                 gamma: float):
        self.env = env
        self.batch_size = batch_size
        self.memory = ReplayBuffer(memory_size, batch_size)
        self.target_update = target_update
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.gamma = gamma

        self.obs_dim = env.observation_space.shape[0]
        self.act_dim = env.action_space.n

        self.dqn = Network(obs_dim, act_dim)
        self.dqn_target = Network(obs_dim, act_dim)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval()

        # self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        # colab은 NVIDA cuda 없어도 걍 GPU 자동으로 돌아가니까 이 코드 필요 없나?

    def train(self, num_episodes: int):
        
        update_cnt = 0

        for iter in range(num_episodes):

            s = self.env.reset()
            d = False
            
            while(not d):
                if self.epsilon > np.random.ramdom():
                    a = self.env.action_space.sample()
                else:
                    a = self.dqn.forward(torch.FloatTensor(s)).argmax()
                    a = a.detach().cpu().numpy()    ## a가 tensor 객체라서 detach().cpu().numpy()쓰는 건 알겠는데, 그냥 a.numpy() 쓰면 안 되는건가?

                next_s, r, d, _ = self.env.step(a)
                self.memory.store(s, a, r, next_s, d)
                s = next_s

                if len(self.memory) >= self.batch_size:
                    loss = self.update_model()
                    update_cnt += 1

                    self.epsilon = max(self.min_epsilon,
                                    self.epsilon - self.epsilon_decay * (self.max_epsilon - min_epsilon))

                    if update_cnt % self.target_update == 0:
                        self.dqn_target.load_state_dict(self.dqn.state_dict())

            
    def update_model(self):
        train_batch = self.memory.sample_batch()

        loss = self.compute_loss(train_batch)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()


    def compute_loss(self, train_batch):
        s = torch.FloatTensor(np.array([i[0] for i in train_batch]))
        a = torch.LongTensor(np.array([i[1] for i in train_batch])).view([-1, 1])
        r = torch.FloatTensor(np.array([i[2] for i in train_batch])).view([-1, 1])
        next_s = torch.FloatTensor(np.array([i[4] for i in train_batch]))
        d = torch.BoolTensor(np.array([i[3] for i in train_batch])).view([-1, 1])
        
        curr_value = self.dqn(s).gather(1, a)
        next_value = self.dqn_target(next_s).max(dim=1, keepdim=True)[0].detach()

        mask = 1 - done
        target = (r + self.gamma * next_value * mask)

        loss = F.smooth_l2_loss(curr_value, target)

        return loss