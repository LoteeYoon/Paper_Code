{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_CartPole-v0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUkcjb6wXqe_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oByXC2APc5JY"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import gym\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sys, os\r\n",
        "from IPython.display import clear_output\r\n",
        "from typing import List"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKE0VhvODlcA"
      },
      "source": [
        "class Network(nn.Module):\r\n",
        "    def __init__(self, obs_dim: int, act_dim: int):\r\n",
        "        super(Network, self).__init__()\r\n",
        "\r\n",
        "        self.obs_dim = obs_dim\r\n",
        "        self.act_dim = act_dim\r\n",
        "        self.fc1 = nn.Linear(self.obs_dim, 128)\r\n",
        "        self.fc2 = nn.Linear(128, 128)\r\n",
        "        self.fc3 = nn.Linear(128, self.act_dim)\r\n",
        "\r\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxbfsp_NWELI"
      },
      "source": [
        "class ReplayBuffer:\r\n",
        "    def __init__(self, memory_size: int, batch_size: int):\r\n",
        "        self.size = 0\r\n",
        "        self.transition_size = 5    ## transition s, a, r, s', d\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.max_size = memory_size\r\n",
        "        self.replay = np.zeros([memory_size, self.transition_size], dtype=np.float32)\r\n",
        "        self.sample_index = []\r\n",
        "        self.train_batch = []\r\n",
        "        self.ptr = 0\r\n",
        "        \r\n",
        "\r\n",
        "    def store(self, \r\n",
        "              prev_obs: List[float],\r\n",
        "              action: float,\r\n",
        "              reward: float,\r\n",
        "              obs: List[float],\r\n",
        "              done: bool,\r\n",
        "              ):\r\n",
        "        transition = [prev_obs, action, reward, obs, done]\r\n",
        "        self.replay[self.ptr] = transition   ####### .insert() 제거함\r\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\r\n",
        "        self.size = min(self.size + 1, self.max_size)\r\n",
        "\r\n",
        "\r\n",
        "    def sample_batch(self) -> List[int]:\r\n",
        "        sample_index = np.random.randint(low=0, high=self.size, size=self.batch_size) ##### self 제거함\r\n",
        "        train_batch = [self.replay[idx] for idx in sample_index] ##### self 제거함\r\n",
        "        return train_batch\r\n",
        "    "
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWmoNC8fEHnZ"
      },
      "source": [
        "class Agent:\r\n",
        "    def __init__(self, \r\n",
        "                 env: gym.Env,\r\n",
        "                 memory_size: int,\r\n",
        "                 batch_size: int,\r\n",
        "                 target_update: int,\r\n",
        "                 epsilon_decay: float,\r\n",
        "                 max_epsilon: float = 1.0,\r\n",
        "                 min_epsilon: float = 0.1,\r\n",
        "                 gamma: float = 0.99):\r\n",
        "        self.env = env\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.memory = ReplayBuffer(memory_size, batch_size)\r\n",
        "        self.target_update = target_update\r\n",
        "        self.epsilon = max_epsilon\r\n",
        "        self.epsilon_decay = epsilon_decay\r\n",
        "        self.max_epsilon = max_epsilon\r\n",
        "        self.min_epsilon = min_epsilon\r\n",
        "        self.gamma = gamma\r\n",
        "\r\n",
        "        self.obs_dim = env.observation_space.shape[0]\r\n",
        "        self.act_dim = env.action_space.n\r\n",
        "\r\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  ####### \r\n",
        "\r\n",
        "        self.dqn = Network(self.obs_dim, self.act_dim).to(self.device)\r\n",
        "        self.dqn_target = Network(self.obs_dim, self.act_dim).to(self.device)\r\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\r\n",
        "        self.dqn_target.eval()\r\n",
        "\r\n",
        "        self.optimizer = optim.Adam(self.dqn.parameters())  ####### optimizer 선언을 안 해줬었네\r\n",
        "\r\n",
        "\r\n",
        "    def update_model(self):\r\n",
        "        train_batch = self.memory.sample_batch()\r\n",
        "\r\n",
        "        loss = self.compute_loss(train_batch)\r\n",
        "\r\n",
        "        self.optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        self.optimizer.step()\r\n",
        "\r\n",
        "        return loss.item()\r\n",
        "\r\n",
        "\r\n",
        "    def compute_loss(self, train_batch):\r\n",
        "\r\n",
        "        with torch.no_grad(): #########\r\n",
        "            s = torch.FloatTensor(np.array([i[0] for i in train_batch])).to(self.device)\r\n",
        "            a = torch.LongTensor(np.array([i[1] for i in train_batch])).view([-1, 1]).to(self.device)\r\n",
        "            r = torch.FloatTensor(np.array([i[2] for i in train_batch])).view([-1, 1]).to(self.device)\r\n",
        "            next_s = torch.FloatTensor(np.array([i[4] for i in train_batch])).to(self.device)\r\n",
        "            d = torch.BoolTensor(np.array([i[3] for i in train_batch])).view([-1, 1]).to(self.device)\r\n",
        "            \r\n",
        "            curr_value = self.dqn(s).gather(1, a)\r\n",
        "            next_value = self.dqn_target(next_s).max(dim=1, keepdim=True)[0].detach()\r\n",
        "\r\n",
        "            mask = 1 - done\r\n",
        "            target = (r + self.gamma * next_value * mask).to(self.device)\r\n",
        "\r\n",
        "        loss = F.smooth_l2_loss(curr_value, target)\r\n",
        "\r\n",
        "        return loss\r\n",
        "\r\n",
        "\r\n",
        "    def train(self, num_episodes: int, plot_interval: int):\r\n",
        "        \r\n",
        "        update_cnt = 0\r\n",
        "        losses = []\r\n",
        "        score = 0\r\n",
        "        scores = []\r\n",
        "\r\n",
        "        for iter in range(num_episodes):\r\n",
        "\r\n",
        "            s = self.env.reset()\r\n",
        "            d = False\r\n",
        "            \r\n",
        "            while (not d):\r\n",
        "                #self.env.render() #######\r\n",
        "\r\n",
        "                if self.epsilon > np.random.rand(): ### rand() 로 변경\r\n",
        "                    a = self.env.action_space.sample()\r\n",
        "                else:\r\n",
        "                    a = self.dqn.forward(torch.FloatTensor(s).to(self.device)).argmax() #######\r\n",
        "                #   a = self.dqn(torch.FloatTensor(s).to(self.device)).argmax()\r\n",
        "                    a = a.detach().cpu().numpy()    \r\n",
        "\r\n",
        "                next_s, r, d, _ = self.env.step(a)\r\n",
        "                self.memory.store(s, a, r, next_s, d)\r\n",
        "                s = next_s\r\n",
        "                score += r\r\n",
        "                \r\n",
        "                if d:\r\n",
        "                    scores.append(score)\r\n",
        "                    score = 0\r\n",
        "\r\n",
        "                if self.memory.size >= self.batch_size:  ## len 제거함\r\n",
        "                    loss = self.update_model()\r\n",
        "                    losses.append(loss)\r\n",
        "                    update_cnt += 1\r\n",
        "\r\n",
        "                    self.epsilon = max(self.min_epsilon,\r\n",
        "                                    self.epsilon - self.epsilon_decay * (self.max_epsilon - min_epsilon))\r\n",
        "\r\n",
        "                    if update_cnt % self.target_update == 0:\r\n",
        "                        self.dqn_target.load_state_dict(self.dqn.state_dict())\r\n",
        "\r\n",
        "                if iter % plot_interval == 0:\r\n",
        "                    clear_output(True)\r\n",
        "                    plt.figure(figsize=(20, 5))\r\n",
        "                    plt.subplot(121)\r\n",
        "                    plt.title('iter %s. score: %s' % (iter, np.mean(scores[-10:]))) ## 가장 최근 10개 에피소드 평균 score 출력\r\n",
        "                    plt.plot(scores)\r\n",
        "                    plt.subplot(122)\r\n",
        "                    plt.title('loss')\r\n",
        "                    plt.plot(losses)\r\n",
        "                    plt.show()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk_VjajadDeq"
      },
      "source": [
        "env = gym.make('CartPole-v0')\r\n",
        "memory_size = 1000\r\n",
        "batch_size = 32\r\n",
        "target_update = 100\r\n",
        "epsilon_decay = 1 / 2000\r\n",
        "\r\n",
        "agent = Agent(env, memory_size, batch_size, target_update, epsilon_decay)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "qyYMKh7Thv7M",
        "outputId": "be5c4296-0419-4ce2-a29f-ed2059f3653a"
      },
      "source": [
        "num_episodes = 100\r\n",
        "plot_interval = 200\r\n",
        "\r\n",
        "agent.train(num_episodes, plot_interval)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-446edd5018d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplot_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-92-85c3f317d1c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_episodes, plot_interval)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-1233c51f46c1>\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, prev_obs, action, reward, obs, done)\u001b[0m\n\u001b[1;32m     19\u001b[0m               ):\n\u001b[1;32m     20\u001b[0m         \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprev_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition\u001b[0m   \u001b[0;31m####### .insert() 제거함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alIN2BnZiOAF",
        "outputId": "3c9a2220-a40f-47dd-db37-2fa6aa1e17f3"
      },
      "source": [
        "size = 10\r\n",
        "tran_size = 5\r\n",
        "\r\n",
        "replay = [[0]* size for _ in range(tran_size)]\r\n",
        "\r\n",
        "print(replay)\r\n",
        "\r\n",
        "s0 = [[1, 2], 3, 4, [5, 6], True] \r\n",
        "s1 = [[2, 3], 4, 5, [6, 7], False]\r\n",
        "\r\n",
        "replay[0] = s0\r\n",
        "replay[1] = s1\r\n",
        "\r\n",
        "print(replay)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[[1, 2], 3, 4, [5, 6], True], [[2, 3], 4, 5, [6, 7], False], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrjAV4ZTqXUB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}